{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "FFMPEG must be installed. Suggest using winget to install on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip show torchvision torchaudio torch transformers librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapen\\OneDrive\\Documents\\GitHub\\VidBot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following model:  openai/whisper-large\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.parsers.audio import OpenAIWhisperParserLocal\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.blob_loaders.youtube_audio import (\n",
    "    YoutubeAudioLoader,\n",
    ")\n",
    "\n",
    "whisper_model_path = \"~/whisper_models\"\n",
    "\n",
    "# Set a flag to use local or remote parsing\n",
    "local = True\n",
    "\n",
    "# YouTube video URLs\n",
    "urls = [\"https://youtu.be/kCc8FmEb1nY\"]\n",
    "\n",
    "# Directory to save audio files\n",
    "save_dir = \"./transcriptions\"\n",
    "\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY\n",
      "[youtube] kCc8FmEb1nY: Downloading webpage\n",
      "[youtube] kCc8FmEb1nY: Downloading ios player API JSON\n",
      "[youtube] kCc8FmEb1nY: Downloading web creator player API JSON\n",
      "[youtube] kCc8FmEb1nY: Downloading m3u8 information\n",
      "[info] kCc8FmEb1nY: Downloading 1 format(s): 140\n",
      "[download] Destination: transcriptions\\Let's build GPT： from scratch, in code, spelled out..m4a\n",
      "[download] 100% of  107.73MiB in 00:00:03 at 29.59MiB/s    \n",
      "[FixupM4a] Correcting container of \"transcriptions\\Let's build GPT： from scratch, in code, spelled out..m4a\"\n",
      "[ExtractAudio] Not converting audio transcriptions\\Let's build GPT： from scratch, in code, spelled out..m4a; file is already in target format m4a\n",
      "Transcribing part transcriptions\\Let's build GPT： from scratch, in code, spelled out..m4a!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapen\\OneDrive\\Documents\\GitHub\\VidBot\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "c:\\Users\\rapen\\OneDrive\\Documents\\GitHub\\VidBot\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:598: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hi everyone. So by now you have probably heard of ChatGPT. It has taken the world and the AI community by storm. And it is a system that allows you to interact with an AI and give it text-based tasks. So for example, we can ask ChatGPT to write us a small haiku about how important it is that people understand AI and then they can use it to improve the world and make it more prosperous. So when we run this, AI Knowledge brings prosperity for all to see, embrace its power. Okay, not bad. And so y'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine doc\n",
    "combined_docs = [doc.page_content for doc in docs]\n",
    "text = \" \".join(combined_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Split them\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)\n",
    "splits = text_splitter.split_text(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
